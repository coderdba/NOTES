=============================================
DIFY 1.3.0 INSTALL 
=============================================
https://dify.ai/
https://github.com/langgenius
https://github.com/langgenius/dify/releases
https://github.com/langgenius/dify/releases/tag/1.3.0

Install stuff: https://docs.dify.ai/getting-started/install-self-hosted/docker-compose

git clone https://github.com/langgenius/dify.git --branch 1.3.0
cd docker
docker compose up -d

http://localhost/install --> to create admin user/pass

==================================
MODEL PROVIDERS
==================================
NameInitialIcon --> Settings --> model provider
Install azure openai plugin (http://localhost/plugins)
Install ollama plugin for local ollama models
Refresh that page
For each added model plugin, do 'add model' and add the model details, api keys etc

-----------
OLLAMA
-----------
Model Type: LLM
Base URL: http://host.docker.internal:11434
Model Name: codellama:7b
Rest of the fields will be picked up by Dify

----------------------
AZURE OPENAI
----------------------
Model Type: LLM
Deployment name: gpt-4o-mini
Endpoint URL: https://x-dev.openai.azure.com/
API KEY: lksjdlskjfls
API Version: 2024-08-01-preview
Base Model: gpt-4o-mini




