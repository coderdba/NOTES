This conversation was generated with Duck.ai (https://duck.ai) using OpenAI's o3-mini null Model. AI chats may display inaccurate or offensive information (see https://duckduckgo.com/duckai/privacy-terms for more info).

====================

User prompt 1 of 4 - 2/23/2025, 12:05:33 PM:
Give me a python program to load into qdrant vectorstore. Input is an excel file with headings as firsf row.

Convert each row into json with keys as the heading text. If there are more than one item in a cell in the form of csv, convert them to array for that column.

Each row in the excel, converted to json should go as a separate document in qdrant.  Add a metadata label "source" with value "ms".

Use langchain 0.3. Use AzureOpenAI gpt-4o mini model and text-embedding-large for embeddings.

o3-mini null:
Below is a complete Python script that uses Pandas to load an Excel file (assuming the first row contains headers), converts each row into a JSON-like Python dictionary (splitting any comma-separated strings into lists), attaches a metadata label "source":"ms", and then adds each document to a Qdrant vector store via LangChain. In this example we use LangChain v0.3, the AzureOpenAI “gpt-4o mini” model as the LLM (if you need it later) and the “text-embedding-large” deployment for embeddings. You should adjust the configuration (such as endpoint, key, index name, etc.) to match your Azure OpenAI and Qdrant setup.

Before running the script, install the required packages (adjust versions if needed):

  pip install pandas openpyxl langchain==0.3.0 qdrant-client

Below is the Python code:

------------------------------------------------------------
#!/usr/bin/env python3
import os
import pandas as pd
import json

# LangChain imports for models and vectorstores
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.docstore.document import Document

# Import the Azure OpenAI wrapper for LLM if needed later (gpt-4o mini)
from langchain.chat_models import AzureChatOpenAI

def process_cell(cell):
    """
    Process each cell in a row. If the cell is a string containing commas,
    split it into a list of stripped values. Otherwise, return the cell as-is.
    """
    if isinstance(cell, str) and ',' in cell:
        # Split on comma and strip whitespace
        return [s.strip() for s in cell.split(',')]
    return cell

def row_to_json(row, headers):
    """
    Given a Pandas Series (row) and the headers list,
    produce a dictionary (json-like) with keys as header names.
    """
    doc = {}
    for header in headers:
        value = row[header]
        # Optionally check for NaN and replace with None
        if pd.isna(value):
            doc[header] = None
        else:
            doc[header] = process_cell(value)
    return doc

def load_excel_as_documents(filename: str):
    # Read Excel file with first row as header. (openpyxl engine handles .xlsx)
    df = pd.read_excel(filename, engine='openpyxl')
    headers = list(df.columns)
    
    docs = []
    for _, row in df.iterrows():
        json_doc = row_to_json(row, headers)
        # Add metadata label "source": "ms"
        metadata = {"source": "ms"}
        # Wrap the json_doc in a Document for LangChain vectorstore ingestion
        # Using json.dumps to store the structured data as text; you could also store the dict as metadata.
        docs.append(Document(page_content=json.dumps(json_doc, ensure_ascii=False), metadata=metadata))
    return docs

def main():
    # Path to your Excel file
    excel_file = 'input.xlsx'  # change as needed

    # Load documents from Excel
    documents = load_excel_as_documents(excel_file)
    
    # Set up AzureOpenAI configuration.
    # Ensure you have the following environment variables set:
    # - AZURE_OPENAI_API_KEY
    # - AZURE_OPENAI_ENDPOINT
    # If not, you can directly assign them here.
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY", "YOUR_AZURE_OPENAI_API_KEY")
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "YOUR_AZURE_OPENAI_ENDPOINT")
    
    # When using Azure OpenAI via LangChain, you typically pass the deployment name and model names.
    # Example for GPT-4o mini LLM. (This example instantiates an LLM, though for vectorstore you need embeddings.)
    llm = AzureChatOpenAI(
        deployment_name="gpt-4o-mini",  # your deployment name for gpt-4o mini
        model_name="gpt-4o-mini",
        temperature=0,
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version="2023-05-15",
        openai_api_key=azure_api_key
    )
    
    # Set up the embeddings model using Azure OpenAI "text-embedding-large" deployment.
    # Make sure to pass appropriate parameters.
    embeddings = OpenAIEmbeddings(
        deployment="text-embedding-large",  # your deployment name for embeddings
        model="text-embedding-large",
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version="2023-05-15",
        openai_api_key=azure_api_key
    )
    
    # Configure Qdrant connection. Adjust host, port, collection name and any other parameters.
    QDRANT_HOST = "localhost"
    QDRANT_PORT = 6333
    COLLECTION_NAME = "my_collection"

    # Instantiate Qdrant vectorstore. If the collection does not exist, it will be created.
    vectorstore = Qdrant.from_documents(
        documents, 
        embeddings,
        url=f"http://{QDRANT_HOST}:{QDRANT_PORT}",
        collection_name=COLLECTION_NAME
    )
    
    print(f"Inserted {len(documents)} documents into Qdrant collection '{COLLECTION_NAME}'.")

if __name__ == "__main__":
    main()

------------------------------------------------------------

Explanation:

1. The function process_cell() checks if a cell is a string containing commas; if so, it splits it into a list. You can adjust the delimiter or logic as needed.
2. row_to_json() converts a DataFrame row to a dictionary using the header names.
3. Each document is created as a LangChain Document with the JSON text as page_content and with metadata {"source": "ms"}.
4. The script sets up the Azure OpenAI parameters for both the LLM (gpt-4o mini) and embeddings (text-embedding-large). Replace the placeholders or ensure your environment variables are set.
5. Finally, it creates a Qdrant vectorstore (using the provided host and port) and adds the documents to a collection named "my_collection".

Adjust paths, keys, endpoints, hosts, ports, deployment names, and model names as needed for your environment.

--------------------

User prompt 2 of 4 - 2/23/2025, 12:07:20 PM:
Add info message for each step start and end.  If any record fails to load log an error with complete json in the log.

Use logger for logging.

o3-mini null:
Below is the updated Python script. This version logs information at the start and finish of each major step and logs an error (with the entire JSON of the row) if any record fails to process. Make sure to adjust configuration values and environment variables as needed.

------------------------------------------------------------
#!/usr/bin/env python3
import os
import json
import logging
import pandas as pd

# LangChain imports for models and vectorstores
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.docstore.document import Document
from langchain.chat_models import AzureChatOpenAI


# Configure logger
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def process_cell(cell):
    """
    Process each cell in a row. If the cell is a string containing commas,
    split it into a list of stripped values. Otherwise, return the cell as-is.
    """
    if isinstance(cell, str) and ',' in cell:
        # Split on comma and strip whitespace
        return [s.strip() for s in cell.split(',')]
    return cell


def row_to_json(row, headers):
    """
    Given a Pandas Series (row) and headers list,
    produce a dictionary (json-like) with keys as header names.
    """
    doc = {}
    for header in headers:
        value = row[header]
        # If the value is NaN, use None
        doc[header] = None if pd.isna(value) else process_cell(value)
    return doc


def load_excel_as_documents(filename: str):
    logger.info("Starting to load Excel file: %s", filename)
    try:
        df = pd.read_excel(filename, engine='openpyxl')
    except Exception as e:
        logger.error("Failed to load Excel file '%s'. Error: %s", filename, e)
        raise

    headers = list(df.columns)
    docs = []
    for index, row in df.iterrows():
        try:
            json_doc = row_to_json(row, headers)
            # Add metadata label "source": "ms"
            metadata = {"source": "ms"}
            # Create document; storing json as a string in page_content.
            doc = Document(page_content=json.dumps(json_doc, ensure_ascii=False), metadata=metadata)
            docs.append(doc)
        except Exception as e:
            logger.error("Error processing record at index %s: %s. Record JSON: %s", index, e, json.dumps(row.to_dict(), ensure_ascii=False))
    logger.info("Completed loading Excel file. Loaded %d documents.", len(docs))
    return docs


def main():
    logger.info("Script started.")
    # Path to your Excel file
    excel_file = 'input.xlsx'  # change as needed

    # Step 1: Load documents from Excel
    logger.info("Step 1: Loading Excel file and converting rows to documents.")
    documents = load_excel_as_documents(excel_file)
    logger.info("Step 1 completed: %d records loaded.", len(documents))
    
    # Step 2: Set up AzureOpenAI configuration.
    logger.info("Step 2: Setting up AzureOpenAI configuration.")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY", "YOUR_AZURE_OPENAI_API_KEY")
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "YOUR_AZURE_OPENAI_ENDPOINT")
    
    # Instantiate LLM, in case you need it later.
    llm = AzureChatOpenAI(
        deployment_name="gpt-4o-mini",  # your deployment name for gpt-4o mini
        model_name="gpt-4o-mini",
        temperature=0,
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version="2023-05-15",
        openai_api_key=azure_api_key
    )
    logger.info("AzureChatOpenAI LLM configured.")
    
    # Setup embeddings model.
    logger.info("Setting up embeddings model.")
    embeddings = OpenAIEmbeddings(
        deployment="text-embedding-large",  # your deployment name for embeddings
        model="text-embedding-large",
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version="2023-05-15",
        openai_api_key=azure_api_key
    )
    logger.info("Embeddings model configured.")
    
    # Step 3: Configure and load documents into Qdrant vectorstore.
    logger.info("Step 3: Connecting to Qdrant and inserting documents.")
    QDRANT_HOST = "localhost"
    QDRANT_PORT = 6333
    COLLECTION_NAME = "my_collection"

    try:
        vectorstore = Qdrant.from_documents(
            documents,
            embeddings,
            url=f"http://{QDRANT_HOST}:{QDRANT_PORT}",
            collection_name=COLLECTION_NAME
        )
        logger.info("Step 3 completed: Inserted %d documents into Qdrant collection '%s'.", len(documents), COLLECTION_NAME)
    except Exception as e:
        logger.error("Failed to insert documents into Qdrant. Error: %s", e)
    
    logger.info("Script completed.")


if __name__ == "__main__":
    main()
------------------------------------------------------------

Explanation of updates:

1. A logger is configured at the beginning using Python’s logging module.
2. Informational messages are logged for the start and end of each step:
   - Loading the Excel file.
   - Converting each row to a document.
   - Setting up Azure OpenAI (LLM and embeddings).
   - Inserting documents into Qdrant.
3. Each record is processed in a try/except block. In case any record fails during processing, an error is logged containing the index, the exception message, and the complete JSON output of that row.
4. Adjust the Excel file path, API keys, endpoint, Qdrant host/port, collection name, and deployment names as needed for your environment.

This script provides comprehensive logging to trace the progress and catch any errors during document processing and loading into Qdrant.

--------------------

User prompt 3 of 4 - 2/23/2025, 12:08:41 PM:
Use environment values for azurechatopenai parameters. Use load_dotenv.  Create a .env file for setting environment


o3-mini null:
Below is an updated Python script that uses python‑dotenv to load environment variables from a .env file. The script now retrieves parameters for AzureChatOpenAI and embeddings from the environment. A sample .env file is provided afterward.

───────────────────────────── script: main.py ──────────────────────────────
#!/usr/bin/env python3
import os
import json
import logging
import pandas as pd
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

# LangChain imports for models and vectorstores
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.docstore.document import Document
from langchain.chat_models import AzureChatOpenAI

# Configure logger
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def process_cell(cell):
    """
    Process each cell in a row. If the cell is a string containing commas,
    split it into a list of stripped values. Otherwise, return the cell as-is.
    """
    if isinstance(cell, str) and ',' in cell:
        return [s.strip() for s in cell.split(',')]
    return cell


def row_to_json(row, headers):
    """
    Given a Pandas Series (row) and headers list,
    produce a dictionary (json-like) with keys as header names.
    """
    doc = {}
    for header in headers:
        value = row[header]
        doc[header] = None if pd.isna(value) else process_cell(value)
    return doc


def load_excel_as_documents(filename: str):
    logger.info("Starting to load Excel file: %s", filename)
    try:
        df = pd.read_excel(filename, engine='openpyxl')
    except Exception as e:
        logger.error("Failed to load Excel file '%s'. Error: %s", filename, e)
        raise

    headers = list(df.columns)
    docs = []
    for index, row in df.iterrows():
        try:
            json_doc = row_to_json(row, headers)
            # Add metadata label "source": "ms"
            metadata = {"source": "ms"}
            # Create document; storing json as a string in page_content.
            doc = Document(page_content=json.dumps(json_doc, ensure_ascii=False), metadata=metadata)
            docs.append(doc)
        except Exception as e:
            logger.error("Error processing record at index %s: %s. Record JSON: %s", 
                         index, e, json.dumps(row.to_dict(), ensure_ascii=False))
    logger.info("Completed loading Excel file. Loaded %d documents.", len(docs))
    return docs


def main():
    logger.info("Script started.")
    
    # Path to your Excel file
    excel_file = 'input.xlsx'  # change as needed

    # Step 1: Load documents from Excel
    logger.info("Step 1: Loading Excel file and converting rows to documents.")
    documents = load_excel_as_documents(excel_file)
    logger.info("Step 1 completed: %d records loaded.", len(documents))
    
    # Step 2: Set up AzureOpenAI configuration using environment variables
    logger.info("Step 2: Setting up AzureOpenAI configuration.")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_version = os.environ.get("AZURE_OPENAI_API_VERSION", "2023-05-15")  # default version if not set

    if not azure_api_key or not azure_endpoint:
        logger.error("Azure OpenAI API key or endpoint not set in environment variables.")
        return

    # Instantiate AzureChatOpenAI LLM
    llm = AzureChatOpenAI(
        deployment_name=os.environ.get("AZURE_CHAT_DEPLOYMENT_NAME", "gpt-4o-mini"),
        model_name=os.environ.get("AZURE_CHAT_MODEL_NAME", "gpt-4o-mini"),
        temperature=0,
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version=azure_api_version,
        openai_api_key=azure_api_key
    )
    logger.info("AzureChatOpenAI LLM configured.")
    
    # Setup embeddings model using environment variables.
    logger.info("Setting up embeddings model.")
    embeddings = OpenAIEmbeddings(
        deployment=os.environ.get("AZURE_EMBEDDING_DEPLOYMENT", "text-embedding-large"),
        model=os.environ.get("AZURE_EMBEDDING_MODEL", "text-embedding-large"),
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version=azure_api_version,
        openai_api_key=azure_api_key
    )
    logger.info("Embeddings model configured.")
    
    # Step 3: Configure and load documents into Qdrant vectorstore.
    logger.info("Step 3: Connecting to Qdrant and inserting documents.")
    QDRANT_HOST = os.environ.get("QDRANT_HOST", "localhost")
    QDRANT_PORT = os.environ.get("QDRANT_PORT", "6333")
    COLLECTION_NAME = os.environ.get("QDRANT_COLLECTION", "my_collection")

    try:
        vectorstore = Qdrant.from_documents(
            documents,
            embeddings,
            url=f"http://{QDRANT_HOST}:{QDRANT_PORT}",
            collection_name=COLLECTION_NAME
        )
        logger.info("Step 3 completed: Inserted %d documents into Qdrant collection '%s'.", len(documents), COLLECTION_NAME)
    except Exception as e:
        logger.error("Failed to insert documents into Qdrant. Error: %s", e)
    
    logger.info("Script completed.")


if __name__ == "__main__":
    main()
───────────────────────────── end of script ──────────────────────────────

───────────────────────────── sample .env file ──────────────────────────────
# Azure OpenAI parameters
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-azure-openai-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2023-05-15

# AzureChatOpenAI deployment and model (for GPT-4o mini)
AZURE_CHAT_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_CHAT_MODEL_NAME=gpt-4o-mini

# Azure Embedding deployment and model (for text-embedding-large)
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-large
AZURE_EMBEDDING_MODEL=text-embedding-large

# Qdrant parameters
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=my_collection
───────────────────────────── end of .env file ──────────────────────────────

Explanation:

1. The script uses python‑dotenv to load environment variables from a .env file at startup.
2. All Azure-related parameters and Qdrant connection details are retrieved from the environment.
3. Informational log messages indicate the start and end of each major step (loading data, configuring models, and database insertion).
4. If a record fails to process, an error is logged along with the complete JSON representation of that row.
5. Make sure to fill in your actual Azure OpenAI API key, endpoint, and other configuration details in the .env file.

Install required packages with:

  pip install pandas openpyxl python-dotenv langchain==0.3.0 qdrant-client

This script can now be run with your environment variables set via the .env file.

--------------------

User prompt 4 of 4 - 2/23/2025, 12:10:20 PM:
Use an api key for qdrant connection. Also, use environment variables for qdrant client also


o3-mini null:
Below is the updated Python script that now also retrieves Qdrant connection details—including an API key—from environment variables. Make sure you have installed the required packages (pandas, openpyxl, python-dotenv, langchain==0.3.0, and qdrant-client) before running this script.

───────────────────────────── script: main.py ──────────────────────────────
#!/usr/bin/env python3
import os
import json
import logging
import pandas as pd
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

# LangChain imports for models and vectorstores
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.docstore.document import Document
from langchain.chat_models import AzureChatOpenAI

# Configure logger
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def process_cell(cell):
    """
    Process each cell in a row. If the cell is a string containing commas,
    split it into a list of stripped values. Otherwise, return the cell as-is.
    """
    if isinstance(cell, str) and ',' in cell:
        return [s.strip() for s in cell.split(',')]
    return cell


def row_to_json(row, headers):
    """
    Given a Pandas Series (row) and headers list,
    produce a dictionary (json-like) with keys as header names.
    """
    doc = {}
    for header in headers:
        value = row[header]
        doc[header] = None if pd.isna(value) else process_cell(value)
    return doc


def load_excel_as_documents(filename: str):
    logger.info("Starting to load Excel file: %s", filename)
    try:
        df = pd.read_excel(filename, engine='openpyxl')
    except Exception as e:
        logger.error("Failed to load Excel file '%s'. Error: %s", filename, e)
        raise

    headers = list(df.columns)
    docs = []
    for index, row in df.iterrows():
        try:
            json_doc = row_to_json(row, headers)
            # Add metadata label "source": "ms"
            metadata = {"source": "ms"}
            # Create Document; storing the JSON as a string in page_content
            doc = Document(page_content=json.dumps(json_doc, ensure_ascii=False), metadata=metadata)
            docs.append(doc)
        except Exception as e:
            logger.error("Error processing record at index %s: %s. Record JSON: %s", 
                         index, e, json.dumps(row.to_dict(), ensure_ascii=False))
    logger.info("Completed loading Excel file. Loaded %d documents.", len(docs))
    return docs


def main():
    logger.info("Script started.")
    
    # Step 1: Load documents from Excel
    excel_file = os.environ.get("EXCEL_FILE", "input.xlsx")
    logger.info("Step 1: Loading Excel file (%s) and converting rows to documents.", excel_file)
    documents = load_excel_as_documents(excel_file)
    logger.info("Step 1 completed: %d records loaded.", len(documents))
    
    # Step 2: Set up Azure OpenAI configuration using environment variables
    logger.info("Step 2: Setting up AzureOpenAI configuration.")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_version = os.environ.get("AZURE_OPENAI_API_VERSION", "2023-05-15")
    
    if not azure_api_key or not azure_endpoint:
        logger.error("Azure OpenAI API key or endpoint not set in environment variables.")
        return

    # Instantiate AzureChatOpenAI LLM
    llm = AzureChatOpenAI(
        deployment_name=os.environ.get("AZURE_CHAT_DEPLOYMENT_NAME", "gpt-4o-mini"),
        model_name=os.environ.get("AZURE_CHAT_MODEL_NAME", "gpt-4o-mini"),
        temperature=0,
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version=azure_api_version,
        openai_api_key=azure_api_key
    )
    logger.info("AzureChatOpenAI LLM configured.")
    
    # Step 3: Set up the embeddings model using environment variables
    logger.info("Step 3: Setting up embeddings model.")
    embeddings = OpenAIEmbeddings(
        deployment=os.environ.get("AZURE_EMBEDDING_DEPLOYMENT", "text-embedding-large"),
        model=os.environ.get("AZURE_EMBEDDING_MODEL", "text-embedding-large"),
        openai_api_type="azure",
        openai_api_base=azure_endpoint,
        openai_api_version=azure_api_version,
        openai_api_key=azure_api_key
    )
    logger.info("Embeddings model configured.")
    
    # Step 4: Connect to Qdrant and insert documents
    logger.info("Step 4: Connecting to Qdrant and inserting documents.")
    QDRANT_HOST = os.environ.get("QDRANT_HOST", "localhost")
    QDRANT_PORT = os.environ.get("QDRANT_PORT", "6333")
    COLLECTION_NAME = os.environ.get("QDRANT_COLLECTION", "my_collection")
    QDRANT_API_KEY = os.environ.get("QDRANT_API_KEY")  # Optional API key for Qdrant
    
    try:
        # Pass the Qdrant API key if provided. The Qdrant client accepts additional keyword arguments.
        vectorstore = Qdrant.from_documents(
            documents,
            embeddings,
            url=f"http://{QDRANT_HOST}:{QDRANT_PORT}",
            collection_name=COLLECTION_NAME,
            api_key=QDRANT_API_KEY  # This parameter is passed to the underlying qdrant-client
        )
        logger.info("Step 4 completed: Inserted %d documents into Qdrant collection '%s'.", len(documents), COLLECTION_NAME)
    except Exception as e:
        logger.error("Failed to insert documents into Qdrant. Error: %s", e)
    
    logger.info("Script completed.")


if __name__ == "__main__":
    main()
───────────────────────────── end of script ──────────────────────────────

───────────────────────────── sample .env file ──────────────────────────────
# Excel file location
EXCEL_FILE=input.xlsx

# Azure OpenAI parameters
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-azure-openai-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2023-05-15

# AzureChatOpenAI deployment and model (for GPT-4o mini)
AZURE_CHAT_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_CHAT_MODEL_NAME=gpt-4o-mini

# Azure Embedding deployment and model (for text-embedding-large)
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-large
AZURE_EMBEDDING_MODEL=text-embedding-large

# Qdrant parameters
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=my_collection
QDRANT_API_KEY=your_qdrant_api_key_here
───────────────────────────── end of .env file ──────────────────────────────

Explanation:

1. The script uses python‑dotenv (via load_dotenv) to load settings from a .env file.  
2. All configuration details for Azure OpenAI (including the API key, endpoint, API version as well as deployment and model names for both chat and embeddings) are pulled from environment variables.  
3. The Qdrant connection now also checks for an API key from the environment variable QDRANT_API_KEY and passes it to the Qdrant.from_documents() constructor.  
4. Informational log messages show the start and completion of each major step, and any errors during document processing or Qdrant insertion will be logged (with the full JSON for problematic records).  

Ensure that you update the .env file with your actual credentials and connection details before running the script.