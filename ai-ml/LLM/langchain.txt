======================
LANGCHAIN
======================
  - Chains (https://python.langchain.com/docs/modules/chains/, https://js.langchain.com/docs/modules/chains)
  - SQL chain (https://python.langchain.com/docs/use_cases/sql/)
  - API chain (https://python.langchain.com/docs/use_cases/apis/, https://js.langchain.com/docs/modules/chains/popular/api)
  - Summarization (https://python.langchain.com/docs/use_cases/summarization/)

  - Azure Open AI
    https://python.langchain.com/docs/integrations/llms/azure_openai/

   - Vectorstore and various ways of asking questions (very good):
     https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed
   - Vectorstore querying with semantic similarity search
     https://medium.com/@alroumi.abdulmajeed/enhancing-semantic-search-with-langchain-vector-databases-and-llama2-70b-chat-94d8dd56a450

Quickstarts
- General: https://python.langchain.com/docs/get_started/quickstart/
- RAG with vectorstore and RunnablePassthrough: https://python.langchain.com/docs/use_cases/question_answering/quickstart/

Chats
- Chat History
  History Chain - https://python.langchain.com/docs/use_cases/question_answering/chat_history/

- Contextualization
  https://python.langchain.com/docs/use_cases/question_answering/streaming/
  https://python.langchain.com/docs/use_cases/question_answering/chat_history/#contextualizing-the-question

- With llama_index
  https://medium.com/@zekaouinoureddine/bring-your-own-data-to-llms-using-langchain-llamaindex-3ddbac8cc9eb (try this for L0)

- Prompt and Context
  https://stackoverflow.com/questions/76947597/how-does-prompttemplate-interact-with-retrievalqa

Tutorials
- Cheatsheet: Many things: https://cheatsheet.md/langchain-tutorials/langchain-prompts.en
- QA with SelfQueryRetriever on own data - various loaders, vectordb queries, and "SelfQueryRetriever"
- QA with ConversationalRetrievalChain - https://scalexi.medium.com/implementing-a-retrieval-augmented-generation-rag-system-with-openais-api-using-langchain-ab39b60b4d9f
  https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed
- ConversationalRetrievalChain - https://www.youtube.com/watch?v=9AXP7tCI9PI (https://github.com/techleadhd/chatgpt-retrieval/blob/main/chatgpt.py)
- Good tutorial with custom text splitter: https://huggingface.co/learn/cookbook/advanced_rag

- Langchain bot with Docker, OpenAI and Streamlit: https://www.docker.com/blog/build-and-deploy-a-langchain-powered-chat-app-with-docker-and-streamlit/
  - https://github.com/amjadraza/langchain-streamlit-docker-template
- Chat: https://blog.langchain.dev/langchain-chat/
- Chat conversation with memory: https://medium.com/@michael.j.hamilton/conversational-memory-with-langchain-82c25e23ec60

Issue Articles
 - Context, 'helpful answer', prompt template: https://stackoverflow.com/questions/76947597/how-does-prompttemplate-interact-with-retrievalqa
 - Multiple answer issue - fixed using conversational retriever - and LLM chain: https://stackoverflow.com/questions/76229432/azureopenai-and-langchain-weird-multiple-answers
    - Vectorstore retreiver for LLMchain - https://github.com/langchain-ai/langchain/discussions/15883
 - Multiple answer issue - fixed with temperature: https://stackoverflow.com/questions/75718913/openai-gpt-3-api-why-do-i-get-different-non-related-random-responses-to-the-sa#
