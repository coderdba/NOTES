==================================================
SESSION ID FROM MCP SERVER - Mcp-Session-Id
==================================================
https://modelcontextprotocol.io/docs/concepts/transports#python-client

Session Management
Streamable HTTP supports stateful sessions to maintain context across multiple requests:

Session Initialization: Servers may assign a session ID during initialization by including it in an Mcp-Session-Id header
Session Persistence: Clients must include the session ID in all subsequent requests using the Mcp-Session-Id header
Session Termination: Sessions can be explicitly terminated by sending an HTTP DELETE request with the session ID

Example session flow:
// Server assigns session ID during initialization
app.post("/mcp", (req, res) => {
  if (req.body.method === "initialize") {
    const sessionId = generateSecureId();
    res.setHeader("Mcp-Session-Id", sessionId);
    // Store session state...
  }
  // Handle request...
});

// Client includes session ID in subsequent requests
fetch("/mcp", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    "Mcp-Session-Id": sessionId,
  },
  body: JSON.stringify(request),
});

Resumability and Redelivery
To support resuming broken connections, Streamable HTTP provides:

Event IDs: Servers can attach unique IDs to SSE events for tracking
Resume from Last Event: Clients can resume by sending the Last-Event-ID header
Message Replay: Servers can replay missed messages from the disconnection point
This ensures reliable message delivery even with unstable network connections.

​
Security Considerations
When implementing Streamable HTTP transport, follow these security best practices:

Validate Origin Headers: Always validate the Origin header on all incoming connections to prevent DNS rebinding attacks
Bind to Localhost: When running locally, bind only to localhost (127.0.0.1) rather than all network interfaces (0.0.0.0)
Implement Authentication: Use proper authentication for all connections
Use HTTPS: Always use TLS/HTTPS for production deployments
Validate Session IDs: Ensure session IDs are cryptographically secure and properly validated
Without these protections, attackers could use DNS rebinding to interact with local MCP servers from remote websites.


=====================================
PYTHON CLIENT CODE - COPILOT 
=====================================
import requests
import json

# Replace this with your actual MCP server URL
MCP_SERVER_URL = "https://your-mcp-server.com/mcp"

# Step 1: Send initialize request
init_request = {
    "jsonrpc": "2.0",
    "id": "init-001",
    "method": "initialize",
    "params": {
        "client": "python-client",
        "version": "1.0"
    }
}

response = requests.post(
    MCP_SERVER_URL,
    headers={
        "Content-Type": "application/json",
        "Accept": "application/json, text/event-stream"
    },
    data=json.dumps(init_request)
)

if response.status_code == 200:
    session_id = response.headers.get("Mcp-Session-Id")
    print("Mcp-Session-Id:", session_id)

    # Step 2: Send a follow-up request using the session ID
    follow_up_request = {
        "jsonrpc": "2.0",
        "id": "req-002",
        "method": "getStatus",
        "params": {}
    }

    follow_up_response = requests.post(
        MCP_SERVER_URL,
        headers={
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Mcp-Session-Id": session_id
        },
        data=json.dumps(follow_up_request)
    )

    print("Follow-up response:", follow_up_response.json())
else:
    print("Failed to initialize session. Status code:", response.status_code)
    print("Response:", response.text)

========================================================================
WITH LANGCHAIN - COPILOT CODE 
========================================================================

Here's a complete example of how to build a Python MCP client using LangChain's MCP adapter to connect to a streamable HTTP MCP server, retrieve tools, and invoke them using a LangChain-compatible agent.

✅ 1. Install Required Packages
pip install langchain-mcp-adapters langgraph "langchain[openai]"

✅ 2. Start a Streamable HTTP MCP Server
You can use the example server provided in the langchain-mcp-adapters GitHub repo: https://github.com/langchain-ai/langchain-mcp-adapters

cd examples/servers/streamable-http-stateless/
uv run mcp-simple-streamablehttp-stateless --port 3000

This will start a server at http://localhost:3000/mcp/

✅ 3. Python Client Code Using LangChain MCP Adapter
import asyncio
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

# Initialize the LLM (you can use any LangChain-compatible model)
llm = ChatOpenAI(model="gpt-4", temperature=0)

async def main():
    # Connect to the MCP server via streamable HTTP
    async with streamablehttp_client("http://localhost:3000/mcp/") as (read, write, _):
        async with ClientSession(read, write) as session:
            await session.initialize()
            print("✅ MCP Session Initialized")

            # Load tools from the MCP server
            tools = await load_mcp_tools(session)
            print(f"🛠️ Loaded Tools: {[tool.name for tool in tools]}")

            # Create a LangChain agent with the tools
            agent = create_react_agent(llm, tools)

            # Invoke the agent with a user query
            response = await agent.ainvoke({
                "messages": [("user", "What is (3 + 5) x 12?")]
            })

            print("🤖 Agent Response:")
            print(response["messages"][-1].content)

if __name__ == "__main__":
    asyncio.run(main())

🧠 What This Does
Connects to a streamable HTTP MCP server.
Initializes a session and retrieves the Mcp-Session-Id internally.
Loads available tools from the server.
Uses a LangChain-compatible LLM to invoke those tools via a ReAct agent.

========================================================================
WITH LANGCHAIN MULTIPLE MCP SERVERS IN ONE CLIENT - COPILOT CODE 
========================================================================

----------------------------------------------------------------------
Client program - not yet getting session ids
----------------------------------------------------------------------
Here’s a complete example of a Python client using MultiServerMCPClient from langchain_mcp_adapters to connect to multiple MCP servers, load tools from each, and use them with a LangChain agent.

✅ 1. Install Required Packages
pip install langchain-mcp-adapters langgraph "langchain[openai]"

✅ 2. Python Client Using MultiServerMCPClient
import asyncio
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools

# Define the MCP server URLs
MCP_SERVERS = [
    "http://localhost:3000/mcp/",
    "http://localhost:3001/mcp/"
]

# Initialize the LLM
llm = ChatOpenAI(model="gpt-4", temperature=0)

async def main():
    # Create a MultiServerMCPClient
    async with MultiServerMCPClient(MCP_SERVERS) as client:
        await client.initialize()
        print("✅ Multi-server MCP session initialized")

        # Load tools from all servers
        tools = await load_mcp_tools(client)
        print(f"🛠️ Loaded tools from multiple servers: {[tool.name for tool in tools]}")

        # Create a LangChain ReAct agent
        agent = create_react_agent(llm, tools)

        # Invoke the agent with a user query
        response = await agent.ainvoke({
            "messages": [("user", "Use any available tools to calculate the square root of 144.")]
        })

        print("🤖 Agent Response:")
        print(response["messages"][-1].content)

if __name__ == "__main__":
    asyncio.run(main())

🧠 What This Does
Connects to multiple MCP servers using MultiServerMCPClient.
Loads tools from all connected servers.
Uses a LangChain-compatible LLM to invoke those tools via a ReAct agent.

----------------------------------------------------------------------
In this client program how to get session id from mcp servers
----------------------------------------------------------------------
✅ Accessing Session IDs from MultiServerMCPClient
Each server connection inside MultiServerMCPClient is a ClientSession object. You can access them like this:

for url, session in client.sessions.items():
    print(f"Server: {url}")
    print(f"Session ID: {session.session_id}")

🔁 Updated Example Snippet
Add this right after await client.initialize() in the previous code:

# Print session IDs for each MCP server
for url, session in client.sessions.items():
    print(f"🔗 Connected to: {url}")
    print(f"🆔 MCP Session ID: {session.session_id}")


---------------------------------------------------------------------------------
mcp servers mounted with fastapi for the two mcp servers in the client example
---------------------------------------------------------------------------------
✅ 1. Install Required Packages
pip install fastapi uvicorn langchain-mcp-adapters

✅ 2. MCP Server 1: Math Tools
from fastapi import FastAPI
from langchain_mcp_adapters.server.fastapi import create_mcp_app
from langchain.tools import tool

@tool
def add_numbers(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b

@tool
def multiply_numbers(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

tools = [add_numbers, multiply_numbers]

app = FastAPI()
app.mount("/mcp", create_mcp_app(tools))

Run it with:
uvicorn server1:app --port 3000

✅ 3. MCP Server 2: Utility Tools
from fastapi import FastAPI
from langchain_mcp_adapters.server.fastapi import create_mcp_app
from langchain.tools import tool

@tool
def reverse_string(text: str) -> str:
    """Reverse a string."""
    return text[::-1]

@tool
def count_words(text: str) -> int:
    """Count the number of words in a string."""
    return len(text.split())

tools = [reverse_string, count_words]

app = FastAPI()
app.mount("/mcp", create_mcp_app(tools))

Run it with:
uvicorn server2:app --port 3001

🧠 Summary
Server 1 (port 3000): Offers math tools (add_numbers, multiply_numbers)
Server 2 (port 3001): Offers utility tools (reverse_string, count_words)
Both are mounted at /mcp and are compatible with MultiServerMCPClient.

--------------------------------------------------------------------------------------
Combine both servers into two separate mcp endpoints in one single fastapi server
--------------------------------------------------------------------------------------
NOTE: THIS MAY NOT BE ENTIRELY CORRECT CODE

You can absolutely run two separate MCP endpoints on a single FastAPI server by mounting two different MCP apps at different paths (e.g., /mcp/math and /mcp/utils).

✅ Combined FastAPI Server with Two MCP Endpoints

from fastapi import FastAPI
from langchain_mcp_adapters.server.fastapi import create_mcp_app
from langchain.tools import tool

# Math tools
@tool
def add_numbers(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b

@tool
def multiply_numbers(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

# Utility tools
@tool
def reverse_string(text: str) -> str:
    """Reverse a string."""
    return text[::-1]

@tool
def count_words(text: str) -> int:
    """Count the number of words in a string."""
    return len(text.split())

# Create MCP apps
math_tools = [add_numbers, multiply_numbers]
utils_tools = [reverse_string, count_words]

math_mcp_app = create_mcp_app(math_tools)
utils_mcp_app = create_mcp_app(utils_tools)

# Main FastAPI app
app = FastAPI()

# Mount each MCP app at a different route
app.mount("/mcp/math", math_mcp_app)
app.mount("/mcp/utils", utils_mcp_app)


🚀 Run the Server
Save this as combined_server.py and run:
uvicorn combined_server:app --port 3000


You’ll now have:

http://localhost:3000/mcp/math → Math tools
http://localhost:3000/mcp/utils → Utility tools









