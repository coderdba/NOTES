====================================
CODELLAMA USING OLLAMA
====================================
Main site: https://ollama.com/library/codellama:13b
How to prompt: https://ollama.ai/blog/how-to-prompt-code-llama
Github: https://ollama.ai/blog/how-to-prompt-code-llama
Huggingface: https://ollama.ai/blog/how-to-prompt-code-llama

==================
INSTALL AND RUN
==================

-------------
ENV VARS
-------------
OLLAMA_HOST=0.0.0.0
OLLAMA_MODELS=C:\opt\LLM\models\ollama
OLLAMA_ORIGINS=http://0.0.0.0:*

-------------
INSTALL
-------------
Download ollama installer file from https://ollama.com/download/windows
Install it
It will install to C:\Users\myusername\AppData\Local\Programs\Ollama

Set environment variable OLLAMA_MODELS = C:\opt\llm\models\ollama
--> this did not seem to help - ollama list did not show any models

--------------------------
USE A SPECIFIC MODEL
--------------------------
Create a file Modelfile.txt with content like the following indicating which model to use:
FROM ./mistral-7b-instruct-v0.1.Q4_K_M.gguf.bin

(NOTE: This was done in c:\opt\LLM\models - can do elsewhere also by giving the whole path instead of ./)

Create a model blob 
- Will get created in the models folder under a 'blob' subfolder
  NOTE: This will use up additional space in the blob subfolder

ollama create example -f Modelfile.txt

ollama list
NAME            ID              SIZE    MODIFIED
example:latest  ea009b1ff01d    4.4 GB  3 minutes ago

Run the model
ollama run example --> 'example' is the name of the local blob model created from the downloaded model
NOTE: This will start an interactive shell

Run Ollama as server
NOTE: This starts the server - but not any specific model. 
      Choose the model in the POST call to generate answers.
ollama serve


=================
Example runs
=================
------
CLI
------
ollama run codellama "Write me a function that outputs the fibonacci sequence"

ollama run codellama:7b-instruct 'You are an expert programmer that writes simple, concise code and explanations. Write a python function to generate the nth fibonacci number.'

ollama run codellama:7b-code '<PRE> def compute_gcd(x, y): <SUF>return result <MID>'

Code review:
ollama run codellama '
Where is the bug in this code?

def fib(n):
    if n <= 0:
        return n
    else:
        return fib(n-1) + fib(n-2)

Writing tests:
ollama run codellama "write a unit test for this function: $(cat example.py)"

Code completion:
ollama run codellama:7b-code '# A simple python function to remove whitespace from a string:'

------
API
------
curl -X POST http://localhost:11434/api/generate -d '{
  "model": "codellama",
  "prompt": "Write me a function that outputs the fibonacci sequence"
}'


