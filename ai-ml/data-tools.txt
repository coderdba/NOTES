	• Apache Beam - for data extract, plugin ML models into it and so on
	• Apache Spark - for historic data
	• Apache Flink - for streaming data
	• Apache Stream - for streaming data
	• Data Flow software
	• Kubeflow - https://www.kubeflow.org/docs/started/introduction/
	• Dremio

==================
APACHE BEAM
==================
https://beam.apache.org/get-started/beam-overview/
Apache Beam is an open source, unified model for defining both batch and streaming data-parallel processing pipelines. Using one of the open source Beam SDKs, you build a program that defines the pipeline. The pipeline is then executed by one of Beam’s supported distributed processing back-ends, which include Apache Flink, Apache Spark, and Google Cloud Dataflow.

Colab code examples: https://beam.apache.org/get-started/an-interactive-overview-of-beam/

==================
APACHE SPARK
==================
https://spark.apache.org/
Apache Spark™ is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.

- Examples: 
- Quick: https://spark.apache.org/examples.html
- Python: https://github.com/apache/spark/tree/master/examples/src/main/python
- Java: https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples
- Scala: https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples
- Streaming Scala: https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples/streaming
- Streaming Java: https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples/streaming

==================
APACHE FLINK
==================
https://flink.apache.org/

Stateful Computations over Data Streams
Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.

==================
APACHE STREAM
==================
https://streams.apache.org/

Overview
Apache Streams unifies a diverse world of digital profiles and online activities into common formats and vocabularies, and makes these datasets accessible across a variety of databases, devices, and platforms for streaming, browsing, search, sharing, and analytics use-cases.

What is Streams?
Apache Streams contains JRE-based modules that developers can use to easily integrate with online data sources and build polyglot indexes of activities, entities, and relationships - all based on public standards such as Activity Streams, or other published organizational standards.

Why use Streams?
Streams contains libraries and patterns for specifying, publishing, and inter-linking schemas, and assists with conversion of activities (posts, shares, likes, follows, etc.) and objects (profiles, pages, photos, videos, etc.) between the representation, format, and encoding preferred by supported data providers (Twitter, Instagram, etc.), and storage services (Cassandra, Elasticsearch, HBase, HDFS, Neo4J, etc.)

Why is Streams important?
The project aims to provide simple two-way data interchange with all popular REST APIs in activity streams formats using a universal protocol. No other active open-source project has this ambitious goal, as well as production-worthy implementations for >10 services. Streams compatibility with multiple storage back-ends and ability to be embedded within any java-based real-time or batch data processing platform ensures that its interoperability features come with little technical baggage.


