Correlation - multiple models:  https://towardsdatascience.com/calculate-similarity-the-most-relevant-metrics-in-a-nutshell-9a43564f533e
Datadog correlation: https://docs.datadoghq.com/dashboards/correlations/ - Datadog searches for other metrics that exhibited anomalous behavior in a time aligned with the area of interest.

** Book: Forecasting: Principles and Practice: https://otexts.com/fpp2/simple-methods.html

TEST DATA GENERATOR
Pandas, Numpy: https://stackoverflow.com/questions/56310849/generate-random-timeseries-data-with-dates
https://www.kdnuggets.com/2022/06/generate-synthetic-timeseries-data-opensource-tools.html

TIME SERIES FORECASTING
- Keras - https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/

LLM
What is LLM:
https://www.analyticsvidhya.com/blog/2023/03/an-introduction-to-large-language-models-llms/#h-what-is-a-large-language-model

Articles:
- Using GPT-J - https://towardsdatascience.com/how-you-can-use-gpt-j-9c4299dd8526

Chunk Size, Chunk Overlap, Tokens:
- https://github.com/hwchase17/langchain/issues/2026
- https://www.pinecone.io/learn/chunking-strategies/
- https://medium.com/@jeevanchavan143/nlp-tokenization-stemming-lemmatization-bag-of-words-tf-idf-pos-7650f83c60be

Context size:
- https://blendingbits.io/p/llm-engineering-context-windows

Free ones:
https://www.listendata.com/2023/03/open-source-chatgpt-models-step-by-step.html#id-06b2ce

Dalai - llama, alpaca:
- Tutorial: https://medium.com/@martin-thissen/llama-alpaca-chatgpt-on-your-local-computer-tutorial-17adda704c23
- Dalai repo: https://github.com/cocktailpeanut/dalai

Alpaca locally:
https://replicate.com/blog/replicate-alpaca

Train with own dataset:
https://www.mlexpert.io/machine-learning/tutorials/alpaca-fine-tuning
- https://github.com/tloen/alpaca-lora

Private LLM: (free)
https://weaviate.io/blog/private-llm
- https://github.com/imartinez/privateGPT
    - Tutorial with venv: https://hackernoon.com/how-to-install-privategpt-a-local-chatgpt-like-instance-with-no-internet-required
- https://github.com/h2oai/h2ogpt

GPT4ALL: (free)
https://gpt4all.io/index.html
- https://docs.gpt4all.io/
- Models (look for model explorer and dropdown): https://gpt4all.io/index.html
- Fine Tuning: https://medium.com/graphcore/fine-tune-gpt-j-a-cost-effective-gpt-4-alternative-for-many-nlp-tasks-67a42f02068d

GPT4All - running it:
Tutorial - https://docs.kanaries.net/articles/gpt4all.en
- https://github.com/nomic-ai/gpt4all

Private GPT: (uses gpt4all)
https://github.com/imartinez/privateGPT
- Private GPT that uses gpt4all
Tutorial: https://bdtechtalks.com/2023/06/01/create-privategpt-local-llm
Training the model - https://levelup.gitconnected.com/training-your-own-llm-using-privategpt-f36f0c4f01ec
Fine Tuning: https://medium.com/graphcore/fine-tune-gpt-j-a-cost-effective-gpt-4-alternative-for-many-nlp-tasks-67a42f02068d

Models:
- https://github.com/eugeneyan/open-llms

Download models (for Private GPT)
- Groovy: https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin (model type gpt4all)
- Snoozy:  https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML/tree/main (model type gpt4all)
    (https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML/blob/main/GPT4All-13B-snoozy.ggmlv3.q8_0.bin)
- Wizardlm: https://huggingface.co/TheBloke/WizardLM-13B-Uncensored-GGML/tree/main (model type gpt4all)

Convert pytorch files to ggml:
- https://github.com/ggerganov/llama.cpp/discussions/1394

H2OGPT:
https://github.com/h2oai/h2ogpt
- llama models: https://huggingface.co/TheBloke

GPT-J VS LLAMA:
https://sapling.ai/llm/gpt-j-vs-llama

LLAMA:
- https://github.com/ggerganov/llama.cpp
- https://github.com/openlm-research/open_llama

LLAMA Models to download (openllama):
- https://huggingface.co/TheBloke/open-llama-13b-open-instruct-GGML/tree/main (ggml)
- https://huggingface.co/SlyEcho/open_llama_7b_ggml/tree/main (ggml?)
- https://huggingface.co/openlm-research/open_llama_13b (pytorch)

MiniGPT:
https://github.com/karpathy/minGPT

Gpt - build your own:
https://jaketae.github.io/study/gpt/
