Correlation - multiple models:  https://towardsdatascience.com/calculate-similarity-the-most-relevant-metrics-in-a-nutshell-9a43564f533e
Datadog correlation: https://docs.datadoghq.com/dashboards/correlations/ - Datadog searches for other metrics that exhibited anomalous behavior in a time aligned with the area of interest.

** Book: Forecasting: Principles and Practice: https://otexts.com/fpp2/simple-methods.html

LLM
What is LLM:
https://www.analyticsvidhya.com/blog/2023/03/an-introduction-to-large-language-models-llms/#h-what-is-a-large-language-model

Chunk Size, Chunk Overlap, Tokens:
- https://github.com/hwchase17/langchain/issues/2026
- https://www.pinecone.io/learn/chunking-strategies/
- https://medium.com/@jeevanchavan143/nlp-tokenization-stemming-lemmatization-bag-of-words-tf-idf-pos-7650f83c60be

Context size:
- https://blendingbits.io/p/llm-engineering-context-windows

Free ones:
https://www.listendata.com/2023/03/open-source-chatgpt-models-step-by-step.html#id-06b2ce

Dalai - llama, alpaca:
- Tutorial: https://medium.com/@martin-thissen/llama-alpaca-chatgpt-on-your-local-computer-tutorial-17adda704c23
- Dalai repo: https://github.com/cocktailpeanut/dalai

Alpaca locally:
https://replicate.com/blog/replicate-alpaca

Train with own dataset:
https://www.mlexpert.io/machine-learning/tutorials/alpaca-fine-tuning
- https://github.com/tloen/alpaca-lora

Private LLM: (free)
https://weaviate.io/blog/private-llm
- https://github.com/imartinez/privateGPT
    - Tutorial with venv: https://hackernoon.com/how-to-install-privategpt-a-local-chatgpt-like-instance-with-no-internet-required
- https://github.com/h2oai/h2ogpt

GPT4ALL: (free)
https://gpt4all.io/index.html
- https://docs.gpt4all.io/
- Models (look for model explorer and dropdown): https://gpt4all.io/index.html
- Fine Tuning: https://medium.com/graphcore/fine-tune-gpt-j-a-cost-effective-gpt-4-alternative-for-many-nlp-tasks-67a42f02068d
Tutorial - https://docs.kanaries.net/articles/gpt4all.en
- https://github.com/nomic-ai/gpt4all
Training - https://levelup.gitconnected.com/training-your-own-llm-using-privategpt-f36f0c4f01ec
https://github.com/imartinez/privateGPT
- Private GPT that uses gpt4all

Models:
- https://github.com/eugeneyan/open-llms

Download models (for Private GPT)
- Groovy: https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin
- Snoozy:  https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML/tree/main 
    (https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML/blob/main/GPT4All-13B-snoozy.ggmlv3.q8_0.bin)
- Wizardlm: https://huggingface.co/TheBloke/WizardLM-13B-Uncensored-GGML/tree/main

H2OGPT:
https://github.com/h2oai/h2ogpt
- llama models: https://huggingface.co/TheBloke

GPT-J VS LLAMA:
https://sapling.ai/llm/gpt-j-vs-llama
