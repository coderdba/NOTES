===================================
POSTGRES ON KUBERNETES
===================================

Basic deployment:
https://www.sumologic.com/blog/kubernetes-deploy-postgres/
https://www.bmc.com/blogs/kubernetes-postgresql/

My Git that uses this: git/coderdba-coding-org/kubernetes/postgres/postgres1

Advanced deployment:
- https://bitnami.com/stack/postgresql/containers
- https://github.com/zalando/postgres-operator --> With Patroni

Postgres docker images:
- https://hub.docker.com/_/postgres
- docker pull postgres:14.0

===================================
PULL DOCKER IMAGE
===================================
# docker pull postgres:14.0

# docker images |grep postgres
postgres                             14.0       6ce504119cc8   6 days ago      374MB

===================================
MOUNT A DISK ON KUBERNETES NODE
===================================
NOTE: As this is a single node cluster - so direct mount is ok - otherwise, it should be nfs, S3 or other mount)

Add a 20GB dynamically allocated virtual disk to the VM/host

----------------------
MOUNT THE DISK
----------------------

- OPTIONAL PARTITIONING
# fdisk /dev/sdb
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table
Building a new DOS disklabel with disk identifier 0x292d7605.

Command (m for help): n
Partition type:
   p   primary (0 primary, 0 extended, 4 free)
   e   extended
Select (default p): p
Partition number (1-4, default 1): 
First sector (2048-41943039, default 2048): 
Using default value 2048
Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): 
Using default value 41943039
Partition 1 of type Linux and of size 20 GiB is set

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.
Syncing disks.

# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   60G  0 disk 
├─sda1   8:1    0  1.9G  0 part /boot
├─sda2   8:2    0   54G  0 part /
└─sda3   8:3    0    4G  0 part 
sdb      8:16   0   20G  0 disk 
└─sdb1   8:17   0   20G  0 part 
sr0     11:0    1 58.3M  0 rom  /run/media/root/VBox_GAs_6.1.26

- MAKE FILESYSTEM (here, without partition on /dev/sdb)
# mkfs.xfs /dev/sdb
mkfs.xfs: /dev/sdb appears to contain a partition table (dos).
mkfs.xfs: Use the -f option to force overwrite.

[root@ksn1 dev]# mkfs.xfs -f /dev/sdb
meta-data=/dev/sdb               isize=512    agcount=4, agsize=1310720 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0, sparse=0
data     =                       bsize=4096   blocks=5242880, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0

- MOUNT
# mount /dev/sdb /data1

# df -k |grep data1
/dev/sdb        20961280     32992  20928288   1% /data1

- MAKE PERMANENT
Enter the following in /etc/fstab
/dev/sdb        /data1        xfs        defaults        0        0

=========================================
CREATE PERSISTENT VOLUME AND VOLUME CLAIM
=========================================
https://www.sumologic.com/blog/kubernetes-deploy-postgres/
https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/

------------------
PERSISTENT VOLUME
------------------
This reserves 5GB of read-write storage at /data1 on the cluster’s node

File pv.yaml:

apiVersion: v1
kind: PersistentVolume
metadata:
  name: postgres-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 5Gi
  accessModes:
  - ReadWriteOnce
  hostPath:
    path: "/data1/postgres"

# kubectl apply -f ./pv.yaml
persistentvolume/postgres-pv-volume created

# kubectl get pv postgres-pv-volume -o wide
NAME                 CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE   VOLUMEMODE
postgres-pv-volume   5Gi        RWO            Retain           Available           manual                  3s    Filesystem

# kubectl describe pv postgres-pv-volume
Name:            postgres-pv-volume
Labels:          type=local
Annotations:     <none>
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:    manual
Status:          Available
Claim:           
Reclaim Policy:  Retain
Access Modes:    RWO
VolumeMode:      Filesystem
Capacity:        5Gi
Node Affinity:   <none>
Message:         
Source:
    Type:          HostPath (bare host directory volume)
    Path:          /data1/postgres
    HostPathType:  
Events:            <none>

------------------------
PERSISTENT VOLUME CLAIM
------------------------

File: pv-claim-1.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pv-claim-1
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi

# kubectl apply -f pv-claim-1.yaml
persistentvolumeclaim/postgres-pv-claim-1 created
 
# kubectl get pvc -o wide
NAME                  STATUS   VOLUME               CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODE
postgres-pv-claim-1   Bound    postgres-pv-volume   5Gi        RWO            manual         17s   Filesystem

# kubectl describe pvc postgres-pv-claim-1
Name:          postgres-pv-claim-1
Namespace:     default
StorageClass:  manual
Status:        Bound
Volume:        postgres-pv-volume
Labels:        <none>
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      5Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Used By:       <none>
Events:        <none>

# kubectl get pv -o wide
NAME                 CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                         STORAGECLASS   REASON   AGE   VOLUMEMODE
postgres-pv-volume   5Gi        RWO            Retain           Bound    default/postgres-pv-claim-1   manual                  54s   Filesystem

~~~~~~~~~~~~
NOTE
~~~~~~~~~~~~
If another claim is created with the same storageClass, it fails - see describe output below.
That is apparently one storageClass 'manual" assigned to a volume cannot be used for more than one claim.
Therefore, deleted the second pvc as it did not get created properly (kubectl delete -f pv-claim-2.yaml).

# kubectl describe pvc postgres-pv-claim-2
Name:          postgres-pv-claim-2
Namespace:     default
StorageClass:  manual
Status:        Pending
Volume:        
Labels:        <none>
Annotations:   <none>
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      
Access Modes:  
VolumeMode:    Filesystem
Used By:       <none>
Events:
  Type     Reason              Age               From                         Message
  ----     ------              ----              ----                         -------
  Warning  ProvisioningFailed  6s (x4 over 50s)  persistentvolume-controller  storageclass.storage.k8s.io "manual" not found

=========================================
CREATE SECRET FOR PASSWORD
=========================================
Let the password be just "password"

# echo "password" | base64
cGFzc3dvcmQK

Then, create a secrets config file and apply it on the cluster:

File: postgres-secrets.yml

apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret-config
type: Opaque
data:
  password: cG9zdGdyZXMK
 
# kubectl apply -f postgres-secrets.yaml

# kubectl describe secret postgres-secret-config
Name:         postgres-secret-config
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
password:  9 bytes

# kubectl edit secret postgres-secret-config
apiVersion: v1
data:
  password: cG9zdGdyZXMK
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"password":"cG9zdGdyZXMK"},"kind":"Secret","metadata":{"annotations":{},"name":"postgres-secret-config","namespace":"default"},"type":"Opaque"}
  creationTimestamp: "2021-10-07T11:41:35Z"
  name: postgres-secret-config
  namespace: default
  resourceVersion: "60867"
  uid: f7402261-fbc9-4401-9fb7-8da2578a4c02
type: Opaque

=========================================
CREATE POSTGRES STATEFULSET
=========================================

File: postgres-sts.yaml

# PostgreSQL StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres1
spec:
  serviceName: postgres1-service
  selector:
    matchLabels:
      app: postgres
  replicas: 1
  template:
    metadata:
      labels:
        app: postgres
    spec:
      volumes:
        - name: postgres-db-disk
          persistentVolumeClaim:
            claimName: postgres-pv-claim-1
      containers:
        - name: postgres
          image: postgres:14.0
          volumeMounts:
          - name: postgres-db-disk
            mountPath: /var/lib/postgresql/data
          env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret-config
                  key: password
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata

# kubectl apply postgres-sts.yaml

# kubectl get sts -o wide
NAME        READY   AGE     CONTAINERS   IMAGES
postgres1   1/1     4m42s   postgres     postgres:14.0

# kubectl get pods --all-namespaces
NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE
default       postgres1-0                                1/1     Running   0          2m51s

Where does its data sit on host:
# ls -l /data1
drwxr-xr-x 3 root root 20 Oct  7 17:35 postgres






