ASM DISK MANAGEMENT

CONTENTS (some TBD)

LIST ASM DISKS
LIST ASM DISK DEVICE MAPPING
LIST CANDIDATE DEVICES TO ADD TO ASM
CREATE ASMLIB DISK
CREATE DISK GROUP
ADD DISK TO DISK GROUP
REMOVE DISK FROM DISK GROUP
MULTIPATH CONFIGURATION

=================
LIST ASM DISKS
=================

> ORACLEASM
$oracleasm listdisks

> KFOD UTILITY

$ $GRID_HOME/bin/kfod
--------------------------------------------------------------------------------
ORACLE_SID ORACLE_HOME
================================================================================
     +ASM1 /u01/app/12.1.0.2.GRD
     +ASM2 /u01/app/12.1.0.2.GRD

$ kfod disks=all

--------------------------------------------------------------------------------
 Disk          Size Path                                     User     Group
================================================================================
   1:     262138 Mb ORCL:ASM001
   2:     262138 Mb ORCL:ASM002
   3:     262138 Mb ORCL:ASM003
   4:     262138 Mb ORCL:ASM004
   5:     262138 Mb ORCL:ASM005

--------------------------------------------------------------------------------
ORACLE_SID ORACLE_HOME
================================================================================
     +ASM1 /u01/app/12.1.0.2.GRD
     +ASM2 /u01/app/12.1.0.2.GRD

============================
LIST ASM DISK DEVICE MAPPING
============================
https://blogs.oracle.com/AlejandroVargas/entry/mapping_asm_disks_to_physical

The following is not working well - it  is not listing 'on device' information.
[root@orcldb2 ~]# /etc/init.d/oracleasm querydisk VOL1
Disk "VOL1" is a valid ASM disk on device [8, 97]

[root@orcldb2 ~]# ls -l /dev | grep 8, | grep 97
brw-rw----   1 root disk     8,      81 Nov  4 13:02 sdg1

========================================
ADD DISK TO DISK GROUP AND REBALANCE
========================================
ARTICLE1: http://vijaydumpa.blogspot.in/2008/01/asm-san-migration-case-study.html
Friday, January 4, 2008
ASM SAN migration Case Study:
Problem: 
I need to remove 3 old SAN disks(size of 150 G each) from my ASM database without any down time.

Server, OS and DB details:
OS: RHEL 4 Update 4 (64 bit)
DB: 10.2.0.3.0
Server: DELL PowerEdgeTM 2950(16G Memory, 4 CPU's(Intel(R) Xeon(R) CPU 5160 @ 3.00GHz))


Procedure:
1. Make sure you have free disks available to add to the ASM diskgroup, before dropping the disk's:

On ASM instance:
sqlplus / as sysdba

set linesize 200;
col path format a20;

select NAME, PATH, MOUNT_STATUS, HEADER_STATUS, MODE_STATUS, TOTAL_MB, FREE_MB
from v$asm_disk;


2. Add new ASM disks to the diskgroup:

alter diskgroup ORADB_DATA01_DG add disk 'ORCL:H_1253_1521';
alter diskgroup ORADB_DATA01_DG add disk 'ORCL:H_1253_1522';
alter diskgroup ORADB_DATA01_DG add disk 'ORCL:H_1253_1523';

alter diskgroup ORADB_DATA01_DG REBALANCE POWER 10; or
alter system set asm_power_limit=10 scope=memory;

-- Check the rebalance operation
select * from v$asm_operation;


Time taken to rebalance the diskgroup: app. 90 min.


3. Identify the disks to drop from the diskgroup:

set linesize 200;
col path format a20;

select NAME, PATH, MOUNT_STATUS, HEADER_STATUS, MODE_STATUS, TOTAL_MB, FREE_MB
from v$asm_disk;

ALTER DISKGROUP ORADB_DATA01_DG DROP DISK B_1530_1091;
ALTER DISKGROUP ORADB_DATA01_DG DROP DISK C_1530_1090;
ALTER DISKGROUP ORADB_DATA01_DG DROP DISK D_1530_1081;

alter diskgroup ORADB_DATA01_DG REBALANCE POWER 10; or
alter system set asm_power_limit=10 scope=memory;

-- Check the rebalance operation
select * from v$asm_operation;


Time taken to rebalance the diskgroup: app. 90 min.


4. Physically removing the disks from the server:

as root only!!!

/etc/init.d/oracleasm deletedisk B_1530_1091
/etc/init.d/oracleasm deletedisk C_1530_1090
/etc/init.d/oracleasm deletedisk D_1530_1081


How to find mapping of ASM disks to Physical Devices?

a.
atlxd215 | +ASM | /dev
> /etc/init.d/oracleasm querydisk H_1253_1521
Disk "H_1253_1521" is a valid ASM disk on device [120, 113]

b.
atlxd215 | +ASM | /dev
> ls -l /dev | grep 120 | grep 113
brwxrwx--- 1 oracle dba 120, 113 Oct 1 10:55 emcpowerh1

[or] 

atlxd215 | +ASM | /dev
> cd oracleasm
atlxd215 | +ASM | /dev/oracleasm
> cd disks

atlxd215 | +ASM | /dev/oracleasm/disks
> ls -lt
total 0
brw-rw---- 1 oracle dba 120, 177 Oct 1 11:04 L_1253_1561
brw-rw---- 1 oracle dba 120, 161 Oct 1 11:04 K_1253_1560
brw-rw---- 1 oracle dba 120, 145 Oct 1 11:04 J_1253_1541
brw-rw---- 1 oracle dba 120, 129 Oct 1 11:03 I_1253_1540
brw-rw---- 1 oracle dba 120, 113 Oct 1 11:03 H_1253_1521
brw-rw---- 1 oracle dba 120, 97 Oct 1 11:03 G_1253_1520
brw-rw---- 1 oracle dba 120, 81 Oct 1 11:03 F_1253_1501
brw-rw---- 1 oracle dba 120, 65 Oct 1 10:59 E_1253_1500

c. 
If you are using multi-path, you will need an additional step to map the physical device to the multi-path device:

as root only!!!

# /sbin/powermt display dev=emcpowerh1


ARTICLE2: http://harvarinder.blogspot.in/2015/01/ora-15031-disk-specification.html
SHOW PARAMETER ASM_DISKSTRING

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
asm_diskstring                       string      ORCL:*

ALTER DISKGROUP DATA01 ADD DISK 'ORCL:DISK04';
ALTER DISKGROUP DATA01 ADD DISK 'ORCL:DISK05' rebalance;

======================================
MOVE A DATAFILE TO ANOTHER DISK GROUP
======================================
NOTE: NEEDS DOWNTIME

http://www.dba-oracle.com/t_migrate_asm_datafiles_from_one_diskgroup_to_another.htm
(stuff below is direct copy from the above website)

Question:  I need to move datafiles from one diskgroup to another ASM diskgroup.  How do I migrate ASM files between diskgroups?

Answer:  Moving data files from one ASM diskgroup to another diskgroup involves these steps:

Step 1: Get the data file name:

select
   file_name
from
   dba_data_files;

Step 2:  Identify the target diskgroup to migrate to:

select
   name
from
   v$asm_diskgroup;

Step 3:  Take the old data file offline:

alter database datafile 
   '+MYDB_OLDDATA/mysid/app_data.nnn' 
offline; 

Step 4:  Copy the datafile to the new diskgroup (using RMAN)

$ rman target / 

connected to target database: TESTDB (DBID=1234) 

RMAN> copy datafile '+MYDB_OLDDATA/mysid/app_data.nnn' to '+MYDB_NEWDATA'; 

Step 6: Get the new filename:

select    
   file_name 
from 
   dba_data_files; 

Step 7: Re-name the data file:

SQL> alter database rename file 
2 '+MYDB_OLDDATA/mysid/app_data.nnn' 
3 to 
4 '+MYDB_NEWDATA/mysid/app_data.nnn';

After Oracle renames the ASM database file in the data dictionary, it will remove the original ASM database file (+MYDB_OLDDATA/mysid/app_data.nnn). 

Step 8: Rename the RMAN data file:

RMAN> switch datafile '+MYDB_NEWDATA/mysid/app_data.nnn' to copy;

Step 9: Use RMAN recovery to the new data file:

RMAN> recover datafile '+MYDB_NEWDATA/mysid/app_data.nnn';

Step 10:  Put the data file online:

RMAN> alter database datafile '+MYDB_NEWDATA/mysid/app_data.nnn' online;

Step 11: Delete the old ASM file from the old diskgroup.
$ ORACLE_SID=+ASM; export ORACLE_SID

$ sqlplus "/ as sysdba"

SQL> ALTER DISKGROUP TESTDB_DATA2 DROP FILE '+TESTDB_OLDDATA/mysid/app_data.nnn';

ARTICLE3: http://asmsupportguy.blogspot.in/2011/11/rebalancing-act.html
Rebalancing act

ASM ensures that file extents are evenly distributed across all disks in a disk group. This is true for the initial file creation and for file resize operations. That means we should always have a balanced space distribution across all disks in a disk group.

Rebalance operation

Disk group rebalance is triggered automatically on ADD, DROP and RESIZE disk operations and on moving a file between hot and cold regions. Running rebalance by explicitly issuing ALTER DISKGROUP ... REBALANCE is called a manual rebalance. We might want to do that to change the rebalance power for example. We can also run the rebalance manually if a disk group becomes unbalanced for any reason.

The POWER clause of the ALTER DISKGROUP ... REBALANCE statement specifies the degree of parallelism of the rebalance operation. It can be set to a minimum value of 0 which halts the current rebalance until the statement is either implicitly or explicitly re-run. A higher values may reduce the total time it takes to complete the rebalance operation.

The ALTER DISKGROUP ... REBALANCE command by default returns immediately so that we can run other commands while the rebalance operation takes place in the background. To check the progress of the rebalance operations we can query V$ASM_OPERATION view.

Three phase power

The rebalance operation has three distinct phases. First, ASM has to come up with the rebalance plan. That will depend on the rebalance reason, disk group size, number of files in the disk group, whether or not partnership has to modified, etc. In any case this shouldn't take more than a couple of minutes.

The second phase is the moving or relocating the extents among the disks in the disk group. This is where the bulk of the time will be spent. As this phase is progressing, ASM will keep track of the number of extents moved, and the actual I/O performance. Based on that it will be calculating the estimated time to completion (GV$ASM_OPERATION.EST_MINUTES). Keep in mind that this is an estimate and that the actual time may change depending on the overall (mostly disk related) load. If the reason for the rebalance was a failed disk(s) in a redundant disk group, at the end of this phase the data mirroring is fully re-established.

The third phase is disk(s) compacting (ASM version 11.1.0.7 and later). The idea of the compacting phase is to move the data as close to the outer tracks of the disks as possible. Note that at this stage or the rebalance, the EST_MINUTES will keep showing 0. This is a 'feature' that will hopefully be addressed in the future. The time to complete this phase will again depend on the number of disks, reason for rebalance, etc. Overall time should be a fraction of the second phase.

Some notes about rebalance operations
Rebalance is per file operation.
An ongoing rebalance is restarted if the storage configuration changes either when we alter the configuration, or if the configuration changes due to a failure or an outage. If the new rebalance fails because of a user error a manual rebalance may be required.
There can be one rebalance operation per disk group per ASM instance in a cluster.
Rebalancing continues across a failure of the ASM instance performing the rebalance.
The REBALANCE clause (with its associated POWER and WAIT/NOWAIT keywords) can also be used in ALTER DISKGROUP commands for ADD, DROP or RESIZE disks.
Tuning rebalance operations

If the POWER clause is not specified in an ALTER DISKGROUP statement, or when rebalance is implicitly run by ADD/DROP/RESIZE disk, then the rebalance power defaults to the value of the ASM_POWER_LIMIT initialization parameter. We can adjust the value of this parameter dynamically. Higher power limit should result in a shorter time to complete the rebalance, but this is by no means linear and it will depends on the (storage system) load, available throughput and underlying disk response times.

The power can be changed for a rebalance that is in progress. We just need to issue another ALTER DISKGROUP ... REBALANCE command with different value for POWER. This interrupts the current rebalance and restarts it with modified POWER.

Relevant initialization parameters and disk group attributes

ASM_POWER_LIMIT

The ASM_POWER_LIMIT initialization parameter specifies the default power for disk rebalancing in a disk group. The range of values is 0 to 11 in versions prior to 11.2.0.2. Since version 11.2.0.2 the range of values is 0 to 1024, but that still depends on the disk group compatibility (see the notes below). The default value is 1. A value of 0 disables rebalancing.
For disk groups with COMPATIBLE.ASM set to 11.2.0.2 or greater, the operational range of values is 0 to 1024 for the rebalance power.
For disk groups that have COMPATIBLE.ASM set to less than 11.2.0.2, the operational range of values is 0 to 11 inclusive.
Specifying 0 for the POWER in the ALTER DISKGROUP REBALANCE command will stop the current rebalance operation (unless you hit bug 7257618).
_DISABLE_REBALANCE_COMPACT

Setting initialization parameter _DISABLE_REBALANCE_COMPACT=TRUE will disable the compacting phase of the disk group rebalance - for all disk groups.

_REBALANCE_COMPACT

This is a hidden disk group attribute. Setting _REBALANCE_COMPACT=FALSE will disable the compacting phase of the disk group rebalance - for that disk group only.

_ASM_IMBALANCE_TOLERANCE

This initialization parameter controls the percentage of imbalance between disks. Default value is 3%.

Processes

The following table has a brief summary of the background processes involved in the rebalance operation.


Process	Description
ARBn	ASM Rebalance Process. Rebalances data extents within an ASM disk group. Possible processes are ARB0-ARB9 and ARBA.
RBAL	ASM Rebalance Master Process. Coordinates rebalance activity. In an ASM instance, it coordinates rebalance activity for disk groups. In a database instances, it manages ASM disk groups.
Xnnn	Exadata only - ASM Disk Expel Slave Process. Performs ASM post-rebalance activities. This process expels dropped disks at the end of an ASM rebalance.
When a rebalance operation is in progress, the ARBn processes will generate trace files in the background dump destination directory, showing the rebalance progress.

Views

In an ASM instance, V$ASM_OPERATION displays one row for every active long running ASM operation executing in the current ASM instance. GV$ASM_OPERATION will show cluster wide operations.

During the rebalance, the OPERATION will show REBAL, STATE will shows the state of the rebalance operation, POWER will show the rebalance power and EST_MINUTES will show an estimated time the operation should take.

In an ASM instance, V$ASM_DISK displays information about ASM disks. During the rebalance, the STATE will show the current state of the disks involved in the rebalance operation.

Is your disk group balanced

Run the following query in your ASM instance to get the report on the disk group imbalance.

SQL> column "Diskgroup" format A30 
SQL> column "Imbalance" format 99.9 Heading "Percent|Imbalance"
SQL> column "Variance" format 99.9 Heading "Percent|Disk Size|Variance"
SQL> column "MinFree" format 99.9 Heading "Minimum|Percent|Free"
SQL> column "DiskCnt" format 9999 Heading "Disk|Count"
SQL> column "Type" format A10 Heading "Diskgroup|Redundancy"

SQL> SELECT g.name "Diskgroup",
  100*(max((d.total_mb-d.free_mb)/d.total_mb)-min((d.total_mb-d.free_mb)/d.total_mb))/max((d.total_mb-d.free_mb)/d.total_mb) "Imbalance",
  100*(max(d.total_mb)-min(d.total_mb))/max(d.total_mb) "Variance",
  100*(min(d.free_mb/d.total_mb)) "MinFree",
  count(*) "DiskCnt",
  g.type "Type"
FROM v$asm_disk d, v$asm_diskgroup g
WHERE d.group_number = g.group_number and
  d.group_number <> 0 and
  d.state = 'NORMAL' and
  d.mount_status = 'CACHED'
GROUP BY g.name, g.type;

                                           Percent Minimum
                                 Percent Disk Size Percent  Disk Diskgroup
Diskgroup                      Imbalance  Variance    Free Count Redundancy
------------------------------ --------- --------- ------- ----- ----------
ACFS                                  .0        .0    12.5     2 NORMAL
DATA                                  .0        .0    48.4     2 EXTERN
PLAY                                 3.3        .0    98.1     3 NORMAL
RECO                                  .0        .0    82.9     2 EXTERN

NOTE: The above query is from Oracle Press book Oracle Automatic Storage Management, Under-the-Hood & Practical Deployment Guide, by Nitin Vengurlekar, Murali Vallath and Rich Long.

======================================
REBALANCE TUNING
======================================
https://flashdba.com/2015/04/17/asm-rebalance-too-slow-3-tips-to-improve-rebalance-times/
NOTE:1477905.1 - When Will the Rebalance Complete
What is ASM rebalance compact Phase and how it can be disabled (Doc ID 1902001.1)

1. ADD AND DROP IN SAME COMMAND
alter diskgroup data
add disk  'ORCL:NEWDATA1','ORCL:NEWDATA2','ORCL:NEWDATA3','ORCL:NEWDATA4',
          'ORCL:NEWDATA5','ORCL:NEWDATA6','ORCL:NEWDATA7','ORCL:NEWDATA8'
drop disk 'DATA1','DATA2','DATA3','DATA4',
          'DATA5','DATA6','DATA7','DATA8'
rebalance power 11 wait;

INSTEAD OF
alter diskgroup data
add disk  'ORCL:NEWDATA1','ORCL:NEWDATA2','ORCL:NEWDATA3','ORCL:NEWDATA4',
          'ORCL:NEWDATA5','ORCL:NEWDATA6','ORCL:NEWDATA7','ORCL:NEWDATA8'
rebalance power 11 wait;

AND THEN

alter diskgroup data
drop disk 'DATA1','DATA2','DATA3','DATA4',
          'DATA5','DATA6','DATA7','DATA8'
rebalance power 11 wait;

2. Set higher power limit - can go up to 1024 in 11g and up

3. Avoid The Compact Phase (for Flash Storage Systems)
In flash storage, where data resides does not matter - so compacting data is not necessary
What is ASM rebalance compact Phase and how it can be disabled (Doc ID 1902001.1)

11g: _DISABLE_REBALANCE_COMPACT=TRUE
12c: ALTER DISKGROUP  SET ATTRIBUTE "_rebalance_compact‚Äù="FALSE";


======================================
REBALANCE - RISKS
======================================
https://kevinclosson.net/2016/08/21/stop-constantly-adding-disks-to-your-asm-disk-groups-resize-your-asm-disks-on-all-flash-array-storage-adding-disks-is-really-the-y2k-way-heres-why/
In other words, with the add-disk method administrators are a) making changes in the array, making changes in the Operating System 
and physically rebalancing existing data and doing so in a maintenance window or with a low rebalance power limit and likely 
causing data placement skew.

The resize-disk approach makes no changes and causes no disruption and is nearly immediate. It is a task administrators can 
perform outside maintenance windows.

=======================================
FAST MIRROR RESYNCH, FAST REBALANCE
=======================================
http://jeyaseelan-m.blogspot.in/2011/08/fast-mirror-resync-and-fast-rebalance.html
